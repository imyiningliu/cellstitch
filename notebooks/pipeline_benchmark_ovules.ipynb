{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import imageio\n",
    "from cellpose import models\n",
    "from cellpose import utils as cp_utils\n",
    "from cellstitch.pipeline import *\n",
    "from cellstitch.evaluation import *\n",
    "from cellstitch.utils import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"ovules_subsampled\" # or ovules_subsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Benchmark\n",
    "\n",
    "Comparision between cellstitch (2D), cellpose3D (2.5D), plantseg (3D), cellstitch3D; using the same training set.\n",
    "\n",
    "### PlantSeg\n",
    "- First, created a plantseg virtual enviroment: \n",
    "`conda create -n plant-seg -c pytorch -c conda-forge -c lcerrone -c awolny pytorch=1.9 pytorch-3dunet=1.3.7 plantseg` \n",
    "- activate the environment: `conda activate plant-seg` \n",
    "- download the ovules test dataset: https://osf.io/uzq3w/ to `../data/ovules/plantseg_test/` \n",
    "- set the `path` in `plantseg.yaml` to `../data/ovules/plantseg_test/` \n",
    "- perform segmentation with the `confocal_unet_bce_dice_ds1x` by running `plantseg --config plantseg.yaml`\n",
    "- the predictions are saved to `../data/ovules/plantseg_test/PreProcessing/confocal_unet_bce_dice_ds1x/\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = [\"N_294_final_crop_ds2.npy\", \n",
    "                 \"N_435_final_crop_ds2.npy\",\n",
    "                 \"N_441_final_crop_ds2.npy\",\n",
    "                 \"N_511_final_crop_ds2.npy\",\n",
    "                 \"N_522_final_crop_ds2.npy\",\n",
    "                 \"N_590_final_crop_ds2.npy\",\n",
    "                 \"N_593_final_crop_ds2.npy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantseg_results_folder = \"../data/ovules/plantseg_test/PreProcessing/confocal_unet_bce_dice_ds1x/MultiCut/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_filename in test_filenames: \n",
    "    print(\"Starting %s\" % test_filename) \n",
    "    \n",
    "    with h5py.File(\"%s/%s_predictions_multicut.h5\" % (plantseg_results_folder, test_filename), \"r\") as f:\n",
    "        plantseg = np.array(list(f['segmentation'])) \n",
    "        \n",
    "    plantseg[np.where(plantseg == 1)] = 0 # plantseg use 1 as labels\n",
    "    np.save(\"./results/ovules/pipeline/plantseg/%s.npy\" % test_filename, plantseg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train cellpose model from scratch\n",
    "First, need to prepare training data for cellpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filenames = [\"N_404_ds2x.npy\", \n",
    "                  \"N_405_A_ds2x.npy\", \n",
    "                  \"N_405_B_ds2x.npy\", \n",
    "                  \"N_416_ds2x.npy\",\n",
    "                  \"N_422_ds2x.npy\",\n",
    "                  \"N_425_ds2x.npy\",\n",
    "                  \"N_428_ds2x.npy\",\n",
    "                  \"N_440_ds2x.npy\",\n",
    "                  \"N_445_ds2x.npy\",\n",
    "                  \"N_449_ds2x.npy\",\n",
    "                  \"N_450_ds2x.npy\", \n",
    "                  \"N_451_ds2x.npy\",\n",
    "                  \"N_454_ds2x.npy\",\n",
    "                  \"N_457_ds2x.npy\",\n",
    "                  \"N_458_ds2x.npy\",\n",
    "                  \"N_487_ds2x.npy\",\n",
    "                  \"N_509_ds2x.npy\",\n",
    "                  \"N_512_ds2x.npy\",\n",
    "                   \"N_517_ds2x.npy\",\n",
    "                  \"N_534_ds2x.npy\",\n",
    "                  \"N_535_ds2x.npy\",\n",
    "                  \"N_536_ds2x.npy\"]\n",
    "\n",
    "ovules_folder = \"../DATA/ovules\"\n",
    "cellpose_folder = \"../DATA/ovules/cellpose_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_filename in train_filenames: \n",
    "    img = np.load(\"%s/raw/%s\" % (ovules_folder, train_filename))\n",
    "    labels = np.load(\"%s/labels/%s\" % (ovules_folder, train_filename)) \n",
    "    depth = img.shape[0] \n",
    "    \n",
    "    for i in range(depth): \n",
    "        imageio.imwrite(\"%s/%s_%s.tif\" % (cellpose_folder, train_filename, i), img[i])\n",
    "        imageio.imwrite(\"%s/%s_%s_masks.tif\" % (cellpose_folder, train_filename, i), labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python -m cellpose --train --dir ../DATA/ovules/cellpose_train --pretrained_model None --n_epochs 100  --verbose` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate cellpose3d results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../DATA/ovules/cellpose_train/models/cellpose_residual_on_style_on_concatenation_off_cellpose_train_2023_05_08_09_31_06.231473'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_threshold = 1\n",
    "model = models.CellposeModel(gpu=True, pretrained_model=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_filename in test_filenames: \n",
    "    print(\"Starting %s\" % test_filename)\n",
    "    img = np.load(\"%s/raw/%s\" % (ovules_folder, test_filename)) \n",
    "    masks, _, _ = model.eval(img, do_3D=True, flow_threshold=flow_threshold, channels = [0,0]) \n",
    "    np.save(\"./results/ovules/pipeline/cellpose3d/%s\" % test_filename, masks) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate cellpose2d results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_filename in test_filenames: \n",
    "    print(\"Starting %s\" % test_filename)\n",
    "    img = np.load(\"../DATA/%s/raw/%s\" % (dataset, test_filename)) \n",
    "    masks, _, _ = model.eval(list(img), do_3D=False, flow_threshold=flow_threshold, channels = [0,0])\n",
    "    masks = cp_utils.stitch3D(np.array(masks))\n",
    "    \n",
    "    np.save(\"./results/%s/cellpose2d/%s\" % (dataset, test_filename), masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate cellstitch results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_filename in test_filenames: \n",
    "    print(\"Starting %s\" % test_filename)\n",
    "    img = np.load(\"%s/raw/%s\" % (ovules_folder, test_filename)) \n",
    "    \n",
    "    cellstitch, _, _ = model.eval(list(img), flow_threshold=flow_threshold, channels = [0,0])\n",
    "    cellstitch = np.array(cellstitch)\n",
    "\n",
    "    yz_masks, _, _ = model.eval(list(img.transpose(1,0,2)), flow_threshold=flow_threshold, channels = [0,0])\n",
    "    yz_masks = np.array(yz_masks).transpose(1,0,2)\n",
    "\n",
    "    xz_masks, _, _ = model.eval(list(img.transpose(2,1,0)), flow_threshold=flow_threshold, channels = [0,0])\n",
    "    xz_masks = np.array(xz_masks).transpose(2,1,0)\n",
    "\n",
    "    full_stitch(cellstitch, yz_masks, xz_masks)\n",
    "    \n",
    "    np.save(\"./results/ovules/pipeline/cellstitch/%s\" % test_filename, cellstitch) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# benchmark results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"cellpose2d\" \n",
    "ap_threshold = 0.5\n",
    "\n",
    "data = [] \n",
    "for filename in test_filenames:\n",
    "    print(\"Starting %s\" % filename)\n",
    "    labels = np.load('../DATA/%s/labels/%s' % (dataset, filename)) \n",
    "    \n",
    "    masks = np.load(\"./results/%s/%s/%s\" % (dataset, method, filename))\n",
    "\n",
    "    ap, tp, fp, fn = average_precision(labels, masks, ap_threshold)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    \n",
    "    row = [ \n",
    "        filename, \n",
    "        ap, \n",
    "        tp, \n",
    "        fp, \n",
    "        fn, \n",
    "        precision,\n",
    "        recall\n",
    "    ]\n",
    "    \n",
    "    data.append(row)\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    \"filename\",\n",
    "    \"ap\", \n",
    "    \"tp\", \n",
    "    \"fp\", \n",
    "    \"fn\",\n",
    "    \"precision\",\n",
    "    \"recall\"\n",
    "])\n",
    "\n",
    "df.to_csv(\"./results/%s/%s.csv\" % (dataset, method), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation-aeolus",
   "language": "python",
   "name": "segmentation-aeolus"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
